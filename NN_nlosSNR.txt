import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPRegressor
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt
import numpy as np

# Load the dataset
df = pd.read_csv('SNR_results.csv')

# Reshape the data
snr_columns = df.columns[:15]  # SNR columns
data = []

for _, row in df.iterrows():
    for i, snr in enumerate(row[:15]):
        data.append([i + 1, snr])  # i + 1 represents the MCS index (assuming 1-based index)

# Convert to DataFrame
df_long = pd.DataFrame(data, columns=['MCS_index', 'SNR'])

X = df_long[['MCS_index']]  # MCS index as feature
y = df_long['SNR']  # SNR as target

# Define the range of the SNR values
snr_min = y.min()
snr_max = y.max()
snr_range = snr_max - snr_min

# Store results
results = []

# Loop over different configurations
test_sizes = [0.1, 0.2, 0.3, 0.4, 0.5]
hidden_layer_sizes_list = [(10,), (50,), (100,), (50, 50), (100, 50)]
activation_functions = ['identity', 'logistic', 'tanh', 'relu']

for test_size in test_sizes:
    for hidden_layer_sizes in hidden_layer_sizes_list:
        for activation in activation_functions:
            # Split the data
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)

            # Initialize the MLP Regressor
            model = MLPRegressor(hidden_layer_sizes=hidden_layer_sizes, activation=activation, max_iter=500, random_state=42)

            # Train the model
            model.fit(X_train, y_train)

            # Make predictions
            y_pred = model.predict(X_test)

            # Evaluate the model
            mse = mean_squared_error(y_test, y_pred)
            rmse = np.sqrt(mse)

            # Calculate relative error and estimated accuracy
            relative_error = (rmse / snr_range) * 100
            estimated_accuracy = 100 - relative_error

            # Store results
            results.append({
                'test_size': test_size,
                'hidden_layer_sizes': hidden_layer_sizes,
                'activation': activation,
                'mse': mse,
                'rmse': rmse,
                'relative_error (%)': relative_error,
                'estimated_accuracy (%)': estimated_accuracy
            })

            # Plot Actual vs Predicted SNR
            plt.figure(figsize=(10, 6))
            plt.scatter(y_test, y_pred, edgecolor='k', alpha=0.7)
            plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)  # Line showing perfect prediction
            plt.xlabel('Actual SNR')
            plt.ylabel('Predicted SNR')
            plt.title(f'Actual vs. Predicted SNR\nTest Size: {test_size}, Hidden Layers: {hidden_layer_sizes}, Activation: {activation}')
            plt.show()

# Convert results to DataFrame
results_df = pd.DataFrame(results)

# Find the best configuration based on lowest MSE
best_mse_config = results_df.loc[results_df['mse'].idxmin()]

# Find the best configuration based on highest Estimated Accuracy
best_accuracy_config = results_df.loc[results_df['estimated_accuracy (%)'].idxmax()]

# Print the best configurations
print("Best Configuration Based on Lowest MSE:")
print(best_mse_config)

print("\nBest Configuration Based on Highest Estimated Accuracy:")
print(best_accuracy_config)

# Plotting the Estimated Accuracy
plt.figure(figsize=(10, 6))
for hidden_layer_sizes in hidden_layer_sizes_list:
    for activation in activation_functions:
        subset = results_df[(results_df['hidden_layer_sizes'] == hidden_layer_sizes) & (results_df['activation'] == activation)]
        plt.plot(subset['test_size'], subset['estimated_accuracy (%)'], label=f'Hidden Layers={hidden_layer_sizes}, Activation={activation}', marker='o')

plt.xlabel('Test Size')
plt.ylabel('Estimated Accuracy (%)')
plt.title('Model Accuracy for Different MLP Configurations')
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
