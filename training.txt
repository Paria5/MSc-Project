import pandas as pd
df = pd.read_csv('SNR_results.csv')
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
print(df.head())
# Reshape the data
snr_columns = df.columns[:15]  # SNR columns
data = []

for _, row in df.iterrows():
    for i, snr in enumerate(row[:15]):
        data.append([i + 1, snr])  # i + 1 represents the MCS index (assuming 1-based index)

# Convert to DataFrame
df_long = pd.DataFrame(data, columns=['MCS_index', 'SNR'])

# Check the reshaped data
print(df_long.head())
X = df_long[['MCS_index']]  # MCS index as feature
y = df_long['SNR']  # SNR as target

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error

# Initialize the Random Forest Regressor
model = RandomForestRegressor(n_estimators=100, random_state=42)

# Train the model
model.fit(X_train, y_train)

# Make predictions
y_pred = model.predict(X_test)

# Evaluate the model
mse = mean_squared_error(y_test, y_pred)
print(f'Mean Squared Error: {mse:.2f}')
new_mcs_index = pd.DataFrame({'MCS_index': [4]})  # Example MCS index
predicted_snr = model.predict(new_mcs_index)
print(f'Predicted SNR for MCS index 4: {predicted_snr[0]:.2f}')
throughput=10e6*np.log2(1+10**(predicted_snr/10))
print(f"Predicted Throughput: {throughput} bps")
# Plot 1: Actual vs. Predicted SNR
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred, edgecolor='k', alpha=0.7)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)  # Line showing perfect prediction
plt.xlabel('Actual SNR')
plt.ylabel('Predicted SNR')
plt.title('Actual vs. Predicted SNR')
plt.show()
import numpy as np
import matplotlib.pyplot as plt
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred, edgecolor='k', alpha=0.7)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)  # Line showing perfect prediction
plt.xlabel('Actual SNR')
plt.ylabel('Predicted SNR')
plt.title('Actual vs. Predicted SNR')
plt.show()
# Plot 2: Residuals Plot
residuals = y_test - y_pred
plt.figure(figsize=(10, 6))
plt.scatter(y_pred, residuals, edgecolor='k', alpha=0.7)
plt.axhline(0, color='red', linestyle='--', linewidth=2)
plt.xlabel('Predicted SNR')
plt.ylabel('Residuals')
plt.title('Residuals Plot')
plt.show()
# Plot 3: Distribution of Residuals using Matplotlib
plt.figure(figsize=(10, 6))
plt.hist(residuals, bins=30, edgecolor='k', alpha=0.7)
plt.xlabel('Residuals')
plt.ylabel('Frequency')
plt.title('Distribution of Residuals')
from sklearn.metrics import mean_absolute_error, r2_score

# Calculate other metrics
rmse = np.sqrt(mse)
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f'Root Mean Squared Error: {rmse:.2f}')
print(f'Mean Absolute Error: {mae:.2f}')
print(f'R-squared: {r2:.2f}')
plt.show()
