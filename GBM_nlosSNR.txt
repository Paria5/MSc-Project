import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt
import numpy as np

# Load the dataset
df = pd.read_csv('SNR_results.csv')

# Reshape the data
snr_columns = df.columns[:15]  # SNR columns
data = []

for _, row in df.iterrows():
    for i, snr in enumerate(row[:15]):
        data.append([i + 1, snr])  # i + 1 represents the MCS index (assuming 1-based index)

# Convert to DataFrame
df_long = pd.DataFrame(data, columns=['MCS_index', 'SNR'])

X = df_long[['MCS_index']]  # MCS index as feature
y = df_long['SNR']  # SNR as target

# Define the range of the SNR values
snr_min = y.min()
snr_max = y.max()
snr_range = snr_max - snr_min

# Store results
results = []

# Loop over different configurations
test_sizes = [0.1, 0.2, 0.3, 0.4, 0.5]
n_estimators_list = [50, 100, 200]
learning_rates = [0.01, 0.1, 0.2]

for test_size in test_sizes:
    for n_estimators in n_estimators_list:
        for learning_rate in learning_rates:
            # Split the data
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)

            # Initialize the Gradient Boosting Regressor
            model = GradientBoostingRegressor(n_estimators=n_estimators, learning_rate=learning_rate, random_state=42)

            # Train the model
            model.fit(X_train, y_train)

            # Make predictions
            y_pred = model.predict(X_test)

            # Evaluate the model
            mse = mean_squared_error(y_test, y_pred)
            rmse = np.sqrt(mse)

            # Calculate relative error and estimated accuracy
            relative_error = (rmse / snr_range) * 100
            estimated_accuracy = 100 - relative_error

            # Store results
            results.append({
                'test_size': test_size,
                'n_estimators': n_estimators,
                'learning_rate': learning_rate,
                'mse': mse,
                'rmse': rmse,
                'relative_error (%)': relative_error,
                'estimated_accuracy (%)': estimated_accuracy
            })

            # Plot Actual vs Predicted SNR
            plt.figure(figsize=(10, 6))
            plt.scatter(y_test, y_pred, edgecolor='k', alpha=0.7)
            plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)  # Line showing perfect prediction
            plt.xlabel('Actual SNR')
            plt.ylabel('Predicted SNR')
            plt.title(f'Actual vs. Predicted SNR\nTest Size: {test_size}, n_estimators: {n_estimators}, learning_rate: {learning_rate}')
            plt.show()

# Convert results to DataFrame
results_df = pd.DataFrame(results)

# Print the results
print(results_df)

# Plotting the Estimated Accuracy
plt.figure(figsize=(10, 6))
for n_estimators in n_estimators_list:
    for learning_rate in learning_rates:
        subset = results_df[(results_df['n_estimators'] == n_estimators) & (results_df['learning_rate'] == learning_rate)]
        plt.plot(subset['test_size'], subset['estimated_accuracy (%)'], label=f'n_estimators={n_estimators}, lr={learning_rate}', marker='o')

plt.xlabel('Test Size')
plt.ylabel('Estimated Accuracy (%)')
plt.title('Model Accuracy for Different GBM Configurations')
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()
